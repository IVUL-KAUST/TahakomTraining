{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLt8pdpIZwtV"
      },
      "source": [
        "<h1>Addressing Data Scarcity in Computer Vision<h1>\n",
        "\n",
        "Semi-supervised learning, Few-shot, Zero-shot, and unsupervised learning: How not to label all your data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoAceS9Fe4qU"
      },
      "source": [
        "## Semi-supervised Learning\n",
        "\n",
        "Remember the course:\n",
        "\n",
        "*   A lot of data in the dataset, but...\n",
        "*   ... some labels are missing\n",
        "\n",
        "\n",
        "\n",
        "We will use the pytorch tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py  and adapt it to semi-supervised learning.\n",
        "\n",
        "We will use CIFAR10, a dataset of small images among 10 different classes.\n",
        "The training set normally has 50 000 images and the test set 10 000.\n",
        "\n",
        "This dataset is entirely annotated, so we will artificially remove some labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od-Tm56ziCkJ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# we will keep only 40% of the dataset labelled.\n",
        "# Feel free to try with another value.\n",
        "prop_labelled_elements = 0.4\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: What happens if this is very low? Very high? Run the experiments and report the results."
      ],
      "metadata": {
        "id": "PN6pVZW9iE-N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fQWGQ_NY5MI"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset_train = torchvision.datasets.CIFAR10(\"./data\", download=True, train=True, transform=transform)\n",
        "dataset_val = torchvision.datasets.CIFAR10(\"./data\", download=True, train=False, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKcKkLFe3lX9"
      },
      "source": [
        "We start by splitting the training dataset between\n",
        "\n",
        "\n",
        "*   labelled elements\n",
        "*   unlabelled elements\n",
        "\n",
        "Because our dataset is completely labelled, we artificially remove some labels and set them to -1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K4JNjETkDEL"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)  # for reproducibility\n",
        "indices = np.arange(len(dataset_train))\n",
        "np.random.shuffle(indices)  # mix the indices to not only keep the first N examples labelled.\n",
        "n_labelled_indices = int(len(indices) * prop_labelled_elements)\n",
        "indices_labelled = sorted(indices[:n_labelled_indices])\n",
        "indices_unlabelled = sorted(indices[n_labelled_indices:])\n",
        "\n",
        "for index in indices_unlabelled:\n",
        "    dataset_train.targets[index] = -1  # artificially remove targets\n",
        "\n",
        "dataset_train_labelled = torch.utils.data.Subset(dataset_train, indices_labelled)\n",
        "dataset_train_unlabelled = torch.utils.data.Subset(dataset_train, indices_unlabelled)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3ZTxikzkCD4"
      },
      "source": [
        "train_loader_labelled = torch.utils.data.DataLoader(dataset_train_labelled, batch_size=batch_size, shuffle=True)\n",
        "train_loader_unlabelled = torch.utils.data.DataLoader(dataset_train_unlabelled, batch_size=batch_size)  # No shuffle here, otherwise we won't be able to relabel properly.\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3dv-SSCgu6b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    \"\"\"\n",
        "    From a torch.Tensor to a matplotlib plot.\n",
        "    \"\"\"\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrnXnGRyiT5M"
      },
      "source": [
        "img, label = dataset_val[0]\n",
        "imshow(img)\n",
        "plt.show()\n",
        "print(\"Class:\", dataset_val.classes[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh_ou7Nx3zoO"
      },
      "source": [
        "Here is a toy network we will be using.\n",
        "\n",
        "**Exercise**: Try to improve performance by changing this model (e.g. by using a modern architecture like a ResNet). What happens if the network is pretrained? Not pretrained?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yfw4U1phSzO"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y9SyUs34BP8"
      },
      "source": [
        "Now we define the training, validation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsVUeqeHs2NE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "\n",
        "def train(valloader, trainloader, model, opt, crit, n_epoch=2, loss_every=500):\n",
        "    \"\"\"\n",
        "    Trains the model and plot the losses and accuracy curves.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    losses = []\n",
        "    acc = []\n",
        "    for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "        print(f\"Epoch {epoch}.\")\n",
        "\n",
        "        running_loss = []\n",
        "        running_acc = []\n",
        "        print(\"Train.\")\n",
        "        for i, data in tqdm_notebook(enumerate(trainloader), total=len(trainloader)):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = crit(outputs, labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            running_loss.append(loss.item())\n",
        "            running_acc.append((predicted == labels).sum().item() / labels.size(0))\n",
        "\n",
        "            # compute the running average\n",
        "            if i % loss_every:\n",
        "                losses.append(np.mean(running_loss))\n",
        "                acc.append(np.mean(running_acc))\n",
        "\n",
        "                running_loss = []\n",
        "                running_acc = []\n",
        "\n",
        "        print(\"Val.\")\n",
        "        val_acc = accuracy(valloader, model)\n",
        "        print(f\"Val accuracy: {val_acc}\")\n",
        "    fig, axes = plt.subplots(1, 2)\n",
        "    axes[0].plot(losses)\n",
        "    axes[1].plot(acc)\n",
        "\n",
        "    axes[0].set_ylabel(\"train loss\")\n",
        "    axes[1].set_ylabel(\"train acc\")\n",
        "    plt.show()\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "def accuracy(loader, model):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        loader: data loader to compute the accuracy over\n",
        "        model: network\n",
        "    Returns:\n",
        "        Accuracy of the network over the data\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # remove potential dropout, ...\n",
        "        n_correct = 0\n",
        "        n_total = 0\n",
        "        for i, data in tqdm_notebook(enumerate(loader), total=len(loader)):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            n_correct += (predicted == labels).sum()\n",
        "            n_total += labels.size(0)\n",
        "        return n_correct / n_total\n",
        "\n",
        "\n",
        "def validate(loader, model):\n",
        "    \"\"\"\n",
        "    Plot some predictions of the model, print the accuracy.\n",
        "    \"\"\"\n",
        "    dataiter = iter(loader)\n",
        "    # Get one batch of data\n",
        "    images, labels = next(dataiter)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    accuracy_model = accuracy(loader, model)\n",
        "\n",
        "    # print images\n",
        "    print('Accuracy on test set:', accuracy_model.detach().cpu().item())\n",
        "\n",
        "    imshow(torchvision.utils.make_grid(images[:4].cpu()))\n",
        "    print('GroundTruth: ', ' '.join('%5s' % dataset_val.classes[labels[j]] for j in range(4)))\n",
        "    print('Predicted: ', ' '.join('%5s' % dataset_val.classes[predicted[j]] for j in range(4)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXsagkVg4Gk_"
      },
      "source": [
        "First, we will train a model only on the labelled train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_FV8YMDhpdR"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "net = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** Try different optimizer and lr."
      ],
      "metadata": {
        "id": "CKMTH15TiexP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAWuPq-7hrNn"
      },
      "source": [
        "train(val_loader, train_loader_labelled, net, optimizer, criterion, n_epoch=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGItxPRPhwxu"
      },
      "source": [
        "validate(val_loader, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFc4nL054N29"
      },
      "source": [
        "Now let's predict the labels of the unlabelled set using our trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eswdrNGQL8x"
      },
      "source": [
        "def label_dataset(loader, model):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        All the labels of the data in the loader predicted by the model.\n",
        "        We will use this function to annotate the unlabelled data.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        all_labels = []\n",
        "        for i, data in tqdm_notebook(enumerate(loader), total=len(loader)):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            # COMPLETE HERE\n",
        "            # define a variable `predicted` containing the labels of the current batch.\n",
        "            # You can use the function `torch.argmax(values, dim)`.\n",
        "            outputs = model(inputs)\n",
        "            predicted = ... # TODO\n",
        "            all_labels.append(predicted)\n",
        "        return torch.cat(all_labels, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exPrho9dugOF"
      },
      "source": [
        "labels = label_dataset(train_loader_unlabelled, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft9qEl-j5yCh"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJgSod--4TXG"
      },
      "source": [
        "And let's update the targets of the dataset to match the predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl7AHPMnz5ea"
      },
      "source": [
        "for k, index in enumerate(indices_unlabelled):\n",
        "    dataset_train.targets[index] = labels[k].detach().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfk9n4K74bXt"
      },
      "source": [
        "Finally, let's retrain a model on the larger set with the predicted pseudo-labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k9IexJSjaNJ"
      },
      "source": [
        "net2 = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUh6_VUluerD"
      },
      "source": [
        "train(val_loader, train_loader, net2, optimizer, criterion, n_epoch=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xLW3aaW2hE4"
      },
      "source": [
        "validate(val_loader, net2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPY0txgDKya1"
      },
      "source": [
        "The accuracy should now be greater than for the first network!\n",
        "The pseudo-labelling helped improving the accuracy!\n",
        "\n",
        "**Question**: what would be the limit of accuracy that we could hope to achieve if the method was perfect? Try to compute it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzU0XvU42YF"
      },
      "source": [
        "## Few-shot learning\n",
        "\n",
        "We will see the metric learning approach and define a metric over 2 images.\n",
        "\n",
        "We will continue to use CIFAR as our dataset.\n",
        "\n",
        "Here we will look at 5-shot learning and select 5 examples per class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfaNYlrNloo3"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "# 5-shot learning\n",
        "# try it out with other values. What happens if > 5? And < 5?\n",
        "n_examples_per_class = 5\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr45d936loo5"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset_train = torchvision.datasets.CIFAR10(\"./data\", download=True, train=True, transform=transform)\n",
        "dataset_val = torchvision.datasets.CIFAR10(\"./data\", download=True, train=False, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18rpbNpcloo7"
      },
      "source": [
        "Let's randomly select 5 images per class to represent the images of our class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1qo4ZMuloo9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)  # for reproducibility. Change this value to try different examples in the class\n",
        "indices = np.arange(len(dataset_train))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "n_classes = len(dataset_train.classes)\n",
        "\n",
        "prototypes = [[] for k in range(n_classes)]\n",
        "done = []\n",
        "\n",
        "for k in indices:\n",
        "    img, label = dataset_train[k]\n",
        "    if len(prototypes[label]) < n_examples_per_class:\n",
        "        prototypes[label].append(img)\n",
        "    if label not in done and len(prototypes[label]) == n_examples_per_class:\n",
        "        done.append(label)\n",
        "    if len(done) == n_classes:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtkfg_ZYloo9"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBzCYHG9loo-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNYZw6agloo_"
      },
      "source": [
        "img, label = dataset_val[0]\n",
        "imshow(img)\n",
        "plt.show()\n",
        "print(\"Class:\", dataset_val.classes[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdUh72CqM32J"
      },
      "source": [
        "For the network, we will use a pretrained ResNet50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s71KQrci4317"
      },
      "source": [
        "from torchvision.models import resnet50\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "feature_net = resnet50(pretrained=True).to(device)\n",
        "feature_net.fc = nn.Identity()  # remove the last layer to only get the feature vectors.\n",
        "\n",
        "# We will not learn the model at all.\n",
        "for param in feature_net.parameters():\n",
        "    param.requires_grad_(False)\n",
        "\n",
        "feature_net.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAkdLtMxNRAh"
      },
      "source": [
        "Now let's define the class prototypes by averaging the extracted features of the images of each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAXMTVDrpSRW"
      },
      "source": [
        "class_prototypes = []\n",
        "for k in range(len(prototypes)):\n",
        "    class_images = torch.stack(prototypes[k], dim=0).to(device)\n",
        "    class_prototype = feature_net(class_images).mean(dim=0)  # get the features and average them\n",
        "    class_prototype = class_prototype / class_prototype.norm(dim=-1, keepdim=True)  # normalize the vectors\n",
        "    class_prototypes.append(class_prototype)\n",
        "class_prototypes = torch.stack(class_prototypes, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsqd2UIrORZi"
      },
      "source": [
        "Now let's test the performance!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upmJyr3eqDa1"
      },
      "source": [
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_total = 0\n",
        "    for i, data in tqdm_notebook(enumerate(val_loader), total=len(val_loader)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = feature_net(inputs)\n",
        "        # COMPLETE HERE\n",
        "        # define `similarity` to be the dot product between outputs and class_prototypes.\n",
        "        similarity = ... # TODO\n",
        "        predicted = torch.argmax(similarity, dim=1)\n",
        "        n_correct += (predicted == labels).sum()\n",
        "        n_total += labels.size(0)\n",
        "    accuracy = n_correct / n_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEX9y5witmbX"
      },
      "source": [
        "dataiter = iter(val_loader)\n",
        "images, labels = next(dataiter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "features = feature_net(images)\n",
        "features = features / features.norm(dim=-1, keepdim=True)\n",
        "outputs = features @ class_prototypes.t()\n",
        "\n",
        "predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "# print images\n",
        "print(\"Accuracy on val set: \", accuracy.item())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images[:4].cpu()))\n",
        "print('GroundTruth: ', ' '.join('%5s' % dataset_val.classes[labels[j]] for j in range(4)))\n",
        "print('Predicted: ', ' '.join('%5s' % dataset_val.classes[predicted[j]] for j in range(4)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inuc9j8rt0hX"
      },
      "source": [
        "## Zero-shot learning\n",
        "\n",
        "For zero-shot learning, we will use the Animals with Attributes 2 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqnDk3n1tsEj"
      },
      "source": [
        "# Download the dataset...\n",
        "!wget http://datasets.d2.mpi-inf.mpg.de/xian/xlsa17.zip\n",
        "!unzip xlsa17.zip\n",
        "!wget https://drive.google.com/uc?id=175VTyJROdAOrfccxJY7naRuLWrmJYRc8 -O animal_features.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drbXIdHahZiP"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1bVH1yli99c"
      },
      "source": [
        "data_path = Path(\"/content/xlsa17/data\")\n",
        "awa_base_path = data_path / \"AWA2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3dDfQrLmvsc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBoF2LbbqMbq"
      },
      "source": [
        "We start by defining the datasets we will work on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpUmVcjrhGdy"
      },
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "\n",
        "split = loadmat(awa_base_path / \"att_splits.mat\")\n",
        "features = loadmat(awa_base_path / \"res101.mat\")\n",
        "\n",
        "features, labels = features['features'], features['labels']\n",
        "\n",
        "# Feature vectors\n",
        "features = torch.from_numpy(features.T).to(device)\n",
        "labels = torch.from_numpy(labels[:, 0]).to(device) - 1\n",
        "\n",
        "classes = np.array([name[0].item() for name in split['allclasses_names']])\n",
        "attributes = torch.from_numpy(split['att'].T).to(device, torch.float)\n",
        "test_seen = split['test_seen_loc'][:, 0] - 1\n",
        "test_unseen = split['test_unseen_loc'][:, 0] - 1\n",
        "trainval = split['trainval_loc'][:, 0] - 1\n",
        "\n",
        "attribute_names = np.array(['black', 'white', 'blue', 'brown', 'gray', 'orange', 'red', 'yellow', 'patches', 'spots', 'stripes', 'furry', 'hairless', 'toughskin', 'big', 'small', 'bulbous', 'lean', 'flippers', 'hands', 'hooves', 'pads', 'paws', 'longleg', 'longneck', 'tail', 'chewteeth', 'meatteeth', 'buckteeth', 'strainteeth', 'horns', 'claws', 'tusks', 'smelly', 'flys', 'hops', 'swims', 'tunnels', 'walks', 'fast', 'slow', 'strong', 'weak', 'muscle', 'bipedal', 'quadrapedal', 'active', 'inactive', 'nocturnal', 'hibernate', 'agility', 'fish', 'meat', 'plankton', 'vegetation', 'insects', 'forager', 'grazer', 'hunter', 'scavenger', 'skimmer', 'stalker', 'newworld', 'oldworld', 'arctic', 'coastal', 'desert', 'bush', 'plains', 'forest', 'fields', 'jungle', 'mountains', 'ocean', 'ground', 'water', 'tree', 'cave', 'fierce', 'timid', 'smart', 'group', 'solitary', 'nestspot', 'domestic'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXZN3Tx6lwZZ"
      },
      "source": [
        "print(f\"Number of classes: {len(classes)}\")\n",
        "print(f\"Size of attribute matrix: {attributes.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHKWc2xxmUgl"
      },
      "source": [
        "print(features.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPbPQdTBDI_m"
      },
      "source": [
        "print(trainval.shape)  # only seen classes\n",
        "print(test_seen.shape)\n",
        "print(test_unseen.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVyualXKYyk_"
      },
      "source": [
        "unseen_labels = list(set(labels[test_unseen.tolist()].tolist()))\n",
        "seen_labels = list(set(labels[trainval.tolist()].tolist()))\n",
        "\n",
        "torch_unseen_labels = torch.tensor(unseen_labels).long().to(device)\n",
        "torch_seen_labels = torch.tensor(seen_labels).long().to(device)\n",
        "torch_all_labels = labels.clone()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_omeiXWn4in"
      },
      "source": [
        "# Dataset will all vectors, the train and test set will be subset of this.\n",
        "awa_dataset = torch.utils.data.TensorDataset(features.to(torch.float), labels.to(torch.long))\n",
        "train_dataset = torch.utils.data.Subset(awa_dataset, trainval.tolist())\n",
        "test_unseen_dataset = torch.utils.data.Subset(awa_dataset, test_unseen.tolist())\n",
        "test_seen_dataset = torch.utils.data.Subset(awa_dataset, test_seen.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emdMBr9fp3n2"
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tskvLBEVoCBk"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_unseen_dataloader = torch.utils.data.DataLoader(test_unseen_dataset, batch_size)\n",
        "test_seen_dataloader = torch.utils.data.DataLoader(test_seen_dataset, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46SEp0GlsnjU"
      },
      "source": [
        "Some utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngw_s91-snC5"
      },
      "source": [
        "def train(model, dataloader_train, dataloader_seen, dataloader_unseen,\n",
        "          optimizer, n_epochs=10, unseen_bias=0, compute_train_acc=True,\n",
        "          scheduler=None,\n",
        "          verbose=True):\n",
        "    for epoch in range(n_epochs):\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        acc = train_one_epoch(model, dataloader_train, optimizer, compute_train_acc)\n",
        "        if verbose:\n",
        "            print(f\"Train step: Acc seen: {acc} \")\n",
        "        acc_unseen = \"n/a\"\n",
        "        if dataloader_seen is not None:\n",
        "            total_correct_seen, total_seen = test_one_epoch(model, dataloader_seen, unseen_bias)\n",
        "            acc_seen = total_correct_seen * 100. / float(total_seen)\n",
        "        if dataloader_unseen is not None:\n",
        "            total_correct_unseen, total_unseen = test_one_epoch(model, dataloader_unseen, unseen_bias)\n",
        "            acc_unseen = total_correct_unseen * 100. / float(total_unseen)\n",
        "        if acc_seen != \"n/a\" and acc_unseen != \"n/a\":\n",
        "            acc_harmonic = 2 * acc_seen * acc_unseen / (acc_seen + acc_unseen)\n",
        "        if verbose:\n",
        "            print(f\"Validation step: Acc seen: {acc_seen}, acc unseen: {acc_unseen}, harmonic average: {acc_harmonic}\")\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "    return acc_seen, acc_unseen, acc_harmonic\n",
        "\n",
        "\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, compute_train_acc):\n",
        "    total_num_correct = 0\n",
        "    total_elem = 0\n",
        "    for feature_batch, label_batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(feature_batch)\n",
        "        loss = model.loss(out, label_batch)\n",
        "        if compute_train_acc:\n",
        "            classification_scores = model.predict(out)\n",
        "            _, prediction = torch.max(classification_scores, dim=1)\n",
        "            total_num_correct += torch.sum(prediction == label_batch).tolist()\n",
        "            total_elem += int(label_batch.size(0))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if total_elem == 0:\n",
        "        return 'n/a'\n",
        "    accuracy = total_num_correct * 100. / float(total_elem)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def test_one_epoch(model, dataloader, unseen_bias):\n",
        "    total_num_correct = 0\n",
        "    total_elem = 0\n",
        "    for feature_batch, label_batch in dataloader:\n",
        "        out = model(feature_batch)\n",
        "        loss = model.loss(out, label_batch)\n",
        "        classification_scores = model.predict(out)\n",
        "        prediction = model.prediction(classification_scores, unseen_bias)\n",
        "        total_num_correct += torch.sum(prediction == label_batch).tolist()\n",
        "        total_elem += int(label_batch.size(0))\n",
        "    return total_num_correct, total_elem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQtOEaLISNMY"
      },
      "source": [
        "def pca(features, classes, types, added_points=None, selected_classes=None, figsize=(20, 10), defining_attributes=True):\n",
        "    # TODO: Initialize the PCA model with the desired number of components and apply it to the 'features' variable.\n",
        "    pca_model = ... # Initialize PCA with n_components=2\n",
        "    vectors_embedded_tsne = ... # Apply PCA to the 'features' and get the transformed data\n",
        "    components = pca_model.components_[:2]\n",
        "    if defining_attributes:\n",
        "        highest_indices = np.argsort(components, axis=1)[:, ::-1][:, :3]\n",
        "        highest_values = np.sort(components, axis=1)[:, ::-1][:, :3]\n",
        "        print(\"Defining attributes:\\n\", attribute_names[highest_indices])\n",
        "        print(\"Value:\\n\", highest_values)\n",
        "    if added_points is not None:\n",
        "        added_features, added_classes, added_types = added_points\n",
        "        added_points_projected = pca_model.transform(added_features)\n",
        "        vectors_embedded_tsne = np.concatenate((vectors_embedded_tsne, added_points_projected), axis=0)\n",
        "    else:\n",
        "        added_classes = []\n",
        "        added_types = []\n",
        "    df_tsne = pd.DataFrame(vectors_embedded_tsne, columns=['Component 1', 'Component 2'])\n",
        "    df_tsne['Class'] = classes + added_classes\n",
        "    df_tsne['Type'] = np.array(types + added_types)\n",
        "\n",
        "    if selected_classes is None:\n",
        "        selected_classes = classes\n",
        "\n",
        "    df_tsne = df_tsne[df_tsne['Class'].isin(selected_classes)]\n",
        "    n_classes = len(np.unique(df_tsne['Class']))\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    #palette = sns.color_palette(\"hls\", n_classes)\n",
        "    palette = sns.color_palette(\"hls\", len(np.unique(df_tsne['Type'])))\n",
        "    ax = sns.scatterplot(data=df_tsne, x='Component 1', y='Component 2',\n",
        "                         # hue='Class',\n",
        "                         hue='Type',\n",
        "                         palette=palette,\n",
        "                         # style='Type',\n",
        "                         legend='brief')\n",
        "\n",
        "    for line in range(0, df_tsne.shape[0]):\n",
        "        ax.text(df_tsne['Component 1'][line]+0.01, df_tsne['Component 2'][line],\n",
        "                df_tsne['Class'][line], horizontalalignment='left',\n",
        "                size='medium', color='black', weight='semibold')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4UsBoUJe64H"
      },
      "source": [
        "### Discover the attribute space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shi4vYWqe-pa"
      },
      "source": [
        "types = ['seen' if idx in seen_labels else 'unseen' for idx in range(len(classes))]\n",
        "\n",
        "pca(attributes.cpu().numpy(), list(classes), types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N92csC6GtZMy"
      },
      "source": [
        "### With a linear compatibility function\n",
        "\n",
        "Learn a projection from an **image** feature space to a **semantic** feature space.\n",
        "\n",
        "$$F(x, y; W) = \\theta(x)^T W \\phi(y)$$\n",
        "\n",
        "![image-linear-method](https://drive.google.com/uc?id=16UgDH0vfbv6SSxFzARjWzRoNT_EFJJLS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oOTiWT4qhA3"
      },
      "source": [
        "#### DeViSE\n",
        "[[A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. A.\n",
        "Ranzato, and T. Mikolov. Devise: A deep visual-semantic\n",
        "embedding model. In NIPS, 2013.]](https://www.cs.toronto.edu/~ranzato/publications/frome_nips2013.pdf)\n",
        "\n",
        "Loss function: pairwise ranking objective\n",
        "$$\\sum_{y  \\in \\mathcal{Y}^{tr}}\\max\\left(0, 1_{y_n \\ne y} + F(x_n, y; W) - F(x_n, y_n: W)\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llm3_W6VrQ0Z"
      },
      "source": [
        "def max_margin_loss(predictions, labels):\n",
        "    len_denom = predictions.size(1) - 1\n",
        "    margin = 1 - predictions.gather(1, labels.reshape(-1, 1)) + predictions\n",
        "    zero = torch.tensor(0.).to(labels.device)\n",
        "    # -1 to remove constant when pred[label] = pred[y]\n",
        "    loss = torch.max(margin, zero).sum(dim=1) - 1\n",
        "    return (loss / len_denom).mean()\n",
        "\n",
        "\n",
        "class DeViSEClassification(nn.Module):\n",
        "    def __init__(self, in_feature, semantic_vectors):\n",
        "        super().__init__()\n",
        "\n",
        "        # phi for each y.\n",
        "        self.semantic_vectors = semantic_vectors\n",
        "\n",
        "        # W matrix\n",
        "        self.net = nn.Linear(in_feature, self.semantic_vectors.size(1), bias=False)\n",
        "\n",
        "    def forward(self, features):\n",
        "        \"\"\"\n",
        "        :param features: the theta vector\n",
        "        \"\"\"\n",
        "        return self.net(features)  # theta^T * W\n",
        "\n",
        "    def loss(self, predicted_semantic, labels):\n",
        "        scores = self.predict(predicted_semantic)\n",
        "        probabilities = torch.softmax(scores, dim=-1)\n",
        "        return max_margin_loss(probabilities, labels)\n",
        "\n",
        "    def predict(self, predicted_semantic):\n",
        "        prediction = predicted_semantic @ self.semantic_vectors.transpose(1, 0)\n",
        "        return prediction\n",
        "\n",
        "    def prediction(self, classification_scores, bias):\n",
        "        \"\"\"\n",
        "        Adds bias and return the predicted label for each input\n",
        "        \"\"\"\n",
        "        classification_scores[:, seen_labels] -= bias\n",
        "        _, prediction = torch.max(classification_scores, dim=1)\n",
        "        return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPO5kUGrrror"
      },
      "source": [
        "devise_model = DeViSEClassification(2048, attributes)\n",
        "devise_model.to(device)\n",
        "optimizer = torch.optim.Adam(devise_model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uql12lhQc4w"
      },
      "source": [
        "In practice, we usually only test on the unseen val set.\n",
        "\n",
        "It is complcated to make the models work on both seen and unseen images. Indeed, the model will more easily predict a seen class rather than an unseen one.\n",
        "\n",
        "What is usually done is bias the unseen classes to artificially increase the prediction scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuLgm_C4CmVi"
      },
      "source": [
        "\n",
        "unseen_bias = 10\n",
        "\n",
        "train(devise_model, train_dataloader,\n",
        "      test_seen_dataloader, test_unseen_dataloader,\n",
        "      optimizer,\n",
        "      n_epochs=10,\n",
        "      unseen_bias=unseen_bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** try different values of `unseen_bias` What happens if the bias is low? if it is high?"
      ],
      "metadata": {
        "id": "rdFkv3MkjUjd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AxOzklITMEq"
      },
      "source": [
        "## GANs\n",
        "\n",
        "Not covered here.\n",
        "\n",
        "See here for a notebook on GANs: https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/e9c8374ecc202120dc94db26bf08a00f/dcgan_faces_tutorial.ipynb."
      ]
    }
  ]
}